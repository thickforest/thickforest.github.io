---
layout: post
title: 机器学习之特征归一化（normalization）
categories:
- Pocket
tags:
---
原文地址：https://blog.csdn.net/leiting_imecas/article/details/54986045

收藏时间：2018-04-24 08:58:59

<div  >
<p nodeIndex="20"><span nodeIndex="329">参考自斯坦福机器学习课程</span></p>
<h2 nodeIndex="21"><span nodeIndex="330">  <br nodeIndex="331"></span></h2>
<p nodeIndex="22"><span nodeIndex="332">一 引子</span></p>
<p nodeIndex="23">对房屋售价进行预测时，我们的特征仅有房屋面积一项，但是，在实际生活中，卧室数目也一定程度上影响了房屋售价。下面，我们有这样一组训练样本：</p>
<p nodeIndex="52">注意到，房屋面积及卧室数量两个特征在数值上差异巨大，如果直接将该样本送入训练，则代价函数的轮廓会是“扁长的”，在找到最优解前，梯度下降的过程不仅是曲折的，也是非常耗时的：</p>
<div id="RIL_IMG_1" class="RIL_IMG"><img src="/media/posts_images/2018-04-24-2164855299/1"/></div>
<h2 nodeIndex="54">二 归一化</h2>
<div nodeIndex="55">
<p nodeIndex="56">     该问题的出现是因为我们没有同等程度的看待各个特征，即我们没有将各个特征量化到统一的区间。</p>
<span nodeIndex="342">     数据标准化（归一化）处理是数据挖掘的一项基础工作，不同评价指标往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果，为了消除指标之间的量纲影响，需要进行数据标准化处理，以解决数据指标之间的可比性。原始数据经过数据标准化处理后，各指标处于同一数量级，适合进行综合对比评价。以下是两种常用的归一化方法：</span>

<h3 id="standardization" nodeIndex="58"><span nodeIndex="344">Standardization</span></h3>
<p nodeIndex="59"><span nodeIndex="345">          Standardization</span>又称为<span nodeIndex="346">Z-score normalization</span>，量化后的特征将服从标准正态分布：</p>
<span nodeIndex="347">                             <div id="RIL_IMG_2" class="RIL_IMG"><img src="/media/posts_images/2018-04-24-2164855299/2"/></div>  </span></div>





<p nodeIndex="66">     量化后的特征将分布在<span class="MathJax" id="MathJax-Element-18-Frame" nodeIndex="349"><span class="math" id="MathJax-Span-162" nodeIndex="350"><span nodeIndex="351"><span nodeIndex="352"><span class="mrow" id="MathJax-Span-163" nodeIndex="353"><span class="mo" id="MathJax-Span-164" nodeIndex="354">[</span><span class="mn" id="MathJax-Span-165" nodeIndex="355">0</span><span class="mo" id="MathJax-Span-166" nodeIndex="356">,</span><span class="mn" id="MathJax-Span-167" nodeIndex="357">1</span><span class="mo" id="MathJax-Span-168" nodeIndex="358">]</span></span></span></span></span><span class="MJX_Assistive_MathML" nodeIndex="359">[0,1]</span></span>区间。</p>
<p nodeIndex="67"><span nodeIndex="327">     <span nodeIndex="360">大多数机器学习算法中，会选择Standardization来进行特征缩放，但是，Min-Max Scaling也并非会被弃置一地。在数字图像处理中，像素强度通常就会被量化到</span></span><span nodeIndex="328"><span nodeIndex="361">[0,1]</span><span nodeIndex="362">区间，在一般的神经网络算法中，也会要求特征被量化</span><span nodeIndex="363">[0，1]</span><span nodeIndex="364">区间。</span></span></p>
<p nodeIndex="68"><span nodeIndex="365">     进行了特征缩放以后，代价函数的轮廓会是“偏圆”的，梯度下降过程更加笔直，收敛更快性能因此也得到提升：</span></p>
<span nodeIndex="366"><div id="RIL_IMG_3" class="RIL_IMG"><img src="/media/posts_images/2018-04-24-2164855299/3"/></div></span>  <br nodeIndex="368">
</div>