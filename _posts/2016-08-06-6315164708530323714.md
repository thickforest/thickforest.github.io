---
layout: post
title: Python即时网络爬虫项目:内容提取器的定义
categories:
- 今日头条
tags:
---
摘要

在Python 即时网络爬虫项目启动说明中我们讨论一个数字：程序员浪费在调测内容提取规则上的时间太多了，从而我们发起了这个项目，把程序员从繁琐的调测规则中解放出来，投入到更高端的数据处理工作中。这个项目推出以后受到很大关注，因为开放源码，大家可以在现成源码基础上进一步开发。

1. 项目背景

![](http://p3.pstatp.com/large/b9e0008ab2186bb08da)

在Python即时网络爬虫项目启动说明中我们讨论一个数字：程序员浪费在调测内容提取规则上的时间太多了（见上图），从而我们发起了这个项目，把程序员从繁琐的调测规则中解放出来，投入到更高端的数据处理工作中。

这个项目推出以后受到很大关注，因为开放源码，大家可以在现成源码基础上进一步开发。然而，Python3和Python2是有区别的，《Python即时网络爬虫项目: 内容提取器的定义》 一文的源码无法在Python2.7下使用，本文将发布一个Python2.7的内容提取器。

2. 解决方案

为了解决这个问题，我们把影响通用性和工作效率的提取器隔离出来，描述了如下的数据处理流程图：

![](http://p3.pstatp.com/large/bd90001490d99e4de87)

图中“可插拔提取器”必须很强的模块化，那么关键的接口有：

标准化的输入：以标准的HTML DOM对象为输入标准化的内容提取：使用标准的xslt模板提取网页内容标准化的输出：以标准的XML格式输出从网页上提取到的内容明确的提取器插拔接口：提取器是一个明确定义的类，通过类方法与爬虫引擎模块交互

3. 提取器代码

可插拔提取器是即时网络爬虫项目的核心组件，定义成一个类： GsExtractor 适用python2.7的源代码文件及其说明文档请从 github 下载

使用模式是这样的：

实例化一个GsExtractor对象为这个对象设定xslt提取器，相当于把这个对象配置好（使用三类setXXX()方法）把html dom输入给它，就能获得xml输出（使用extract()方法）

下面是这个GsExtractor类的源代码(适用于Python2.7)

#!/usr/bin/python# -*- coding: utf-8 -*-# 模块名: gooseeker_py2# 类名: GsExtractor# Version: 2.0# 适配Python版本: 2.7# 说明: html内容提取器# 功能: 使用xslt作为模板，快速提取HTML DOM中的内容。# released by 集搜客(http://www.gooseeker.com) on May 18, 2016# github: https://github.com/FullerHua/jisou/core/gooseeker_py2.pyfrom urllib2 import urlopenfrom urllib import quotefrom lxml import etreeimport timeclass GsExtractor(object):

 def _init_(self):

 self.xslt = ""

 # 从文件读取xslt

 def setXsltFromFile(self , xsltFilePath):

 file = open(xsltFilePath , 'r') try:

 self.xslt = file.read() finally:

 file.close() # 从字符串获得xslt

 def setXsltFromMem(self , xsltStr):

 self.xslt = xsltStr # 通过GooSeeker API接口获得xslt

 def setXsltFromAPI(self , APIKey , theme, middle=None, bname=None):

 apiurl = "http://www.gooseeker.com/api/getextractor?key="+ APIKey +"&theme="+quote(theme) if (middle):

 apiurl = apiurl + "&middle="+quote(middle) if (bname):

 apiurl = apiurl + "&bname="+quote(bname)

 apiconn = urlopen(apiurl)

 self.xslt = apiconn.read() # 返回当前xslt

 def getXslt(self):

 return self.xslt # 提取方法，入参是一个HTML DOM对象，返回是提取结果

 def extract(self , html):

 xslt_root = etree.XML(self.xslt)

 transform = etree.XSLT(xslt_root)

 result_tree = transform(html) return result_tree

4. 用法示例

下面是一个示例程序，演示怎样使用GsExtractor类提取豆瓣讨论组话题。本示例有如下特征：

提取器的内容通过GooSeeker平台上的api获得保存结果文件到当前文件夹

下面是源代码，都可从 github 下载

# _*_coding:utf8_*_# douban_py2.py# 爬取豆瓣小组讨论话题# Python版本: 2.7from lxml import etreefrom gooseeker_py2 import GsExtractorfrom selenium import webdriverimport timeclass PhantomSpider:

 def getContent(self, url):

 browser = webdriver.PhantomJS(executable_path='C:\\phantomjs-2.1.1-windows\\bin\\phantomjs.exe')

 browser.get(url)

 time.sleep(3)

 html = browser.execute_script("return document.documentElement.outerHTML")

 output = etree.HTML(html) return output def saveContent(self, filepath, content):

 file_obj = open(filepath, 'w')

 file_obj.write(content)

 file_obj.close()

doubanExtra = GsExtractor() 

# 下面这句调用gooseeker的api来设置xslt抓取规则# 第一个参数是app key，请到GooSeeker会员中心申请# 第二个参数是规则名，是通过GooSeeker的图形化工具: 谋数台MS 来生成的doubanExtra.setXsltFromAPI("ffd5273e213036d812ea298922e2627b" , "豆瓣小组讨论话题") 

url = "https://www.douban.com/group/haixiuzu/discussion?start="totalpages = 5doubanSpider = PhantomSpider()

print("爬取开始")for pagenumber in range(1 , totalpages):

 currenturl = url + str((pagenumber-1)*25)

 print("正在爬取", currenturl)

 content = doubanSpider.getContent(currenturl)

 outputxml = doubanExtra.extract(content)

 outputfile = "result" + str(pagenumber) +".xml"

 doubanSpider.saveContent(outputfile , str(outputxml))

print("爬取结束")

提取结果如下图所示：

![](http://p9.pstatp.com/large/bd90001490ec219e50a)

5. 接下来阅读

本文已经说明了提取器的价值和用法，但是没有说怎样生成它，只有快速生成提取器才能达到节省开发者时间的目的，这个问题将在其他文章讲解，请看《1分钟快速生成用于网页内容提取的xslt模板》

6. 集搜客GooSeeker开源代码下载源

GooSeeker开源Python网络爬虫GitHub源

7. 文档修改历史

2016-08-05：V1.0，Python2.7下的内容提取器类首次发布
